PROMPT: 

Use the following context to give a detailed answer to the question:

QUESTION: Como foi treinado o LSTM?


CONTEXT: ataxadeajustes;moparmetrodeoffset e  dadopors  paramanterafunocontnua(TAYLOR;LETHAM,2017). j j AfunodesazonalidadedenidapelomodelosebaseianassriesdeFourierexpressa daseguintemaneira: N(cid:88) 2nt 2nt s(t) = (a cos( )+b sen( )), (17) n n P P n=1 ondes(t)ovalordasazonalidadenotempot,P representaoperododasrie,N otamanho dasrietemporalea eb socoecientesdasrie(TAYLOR;LETHAM,2017). n n Pararepresentarafunoquedescreveosefeitosdoferiado,consideramosumamatriz deregresses: Z(t) = [1(t  D ),...,1(t  D )], (18) 1 L onde cada feriado i pertence a uma data D e  atribudo uma mudana k representado pela i equao: h(t) = Z(t)k, (19) para essa mudana ainda  incluso efeitos de janelas de dias em volta do feriado (TAYLOR; LETHAM,2017). 4.5 TCNICASDEAPRENDIZADODEMQUINA Aprendizado de mquina  uma sub are da inteligncia articial (IA) que consiste emsistemasque podemaprendercomdadose identicarpadreseesseaprendizado podeser divididoem supervisionado,no supervisionado epor reforo. Osupervisionado  caracterizado peloconjuntodedadossertotalmenterotuladoeomodelosercapazdevericarsenotreinamento a ao estacorreta. Para o tipo nosupervisionado o modelo deve aprender a encontrar e denir os rtulos e, por ltimo, no aprendizado de reforo o modelo  recompensado por uma ao corretaepunidoporumaaoincorreta(MIRJALILI;FARIS;ALJARAH,2020).Nessetrabalho serusadosomenteosupervisionado. 4.5.1 LSTM O modelo Long Short-Term Memory (LSTM), o qual emprega uma arquitetura de redeneuralrecorrente(RNR),queconsisteemnsinterconectadosadaptadosparadadosque envolvemsequencia,foipropostooriginalmenteporHochreiterandSchmidhuberem1997e amplamenteusadonosdiasatuaisporterumasuperioridadeemmodelar,curtaselongasdepen- dncias nos dados(BIANCHI et al., 2017). O LSTM tenta resolver o problema dadissipao do  NEW PAGE  Captulo4. REVISODALITERATURA 14 gradientenoimpondovisnasobservaesrecentes,masmantendoouxodeerroconstante atravsdotempo.ElesediferenciadeoutrasarquiteturasdeRNRapenasporpossuirumaclula. Alm disso, a verso mais simples do LSTM  composta tambm por uma porta de entrada, sada e de esquecer, a qual permite redenir o seu estado. A clula lembra os valores de um intervaloarbitrrioeasportasregulamouxodeinformaoassociadoscomaclula(HOUDT; MOSQUERA;NPOLES,2020). Figura4EstruturainternadoLSTM. Fonte:AutoriaPrpria. Em resumo, a arquitetura do LSTM consiste em um conjunto de blocos de memria ligadosrecursivamente.Aideiaportrsdoblocodememriaseriamanteroestadoduranteum perodo e regular o uxo de informao atravs das portas, de maneira que a sada do bloco sejarecursivamenteligadaaentradadoprximoblocoesuasportas(HOUDT;MOSQUERA; NPOLES,2020).AFigura.4nosmostraessaarquitetura,queenvolveosinaldeentradax(t),a informaocorrenteh(t)eodesaday(t)noinstantetdaclula(YUetal.,2019). OLSTM,comovistonagura.4,podeserexpressocomo: f = (W h +W x +b ), (20) t fh t1 fx t f i = (W h +W x +b ), (21) t ih t1 ix t i c = tanh(W h +W x +b


DETAILED ANSWER:

=======

RESPONSE: 

O LSTM foi treinado usando aprendizado de máquina supervisionado. O aprendizado de máquina supervisionado é caracterizado por um conjunto de dados totalmente rotulados, onde o modelo é capaz de verificar se a ação está correta durante o treinamento. O modelo LSTM usa uma arquitetura de rede neural recorrente (RNR), que consiste em neurônios interconectados adaptados para dados que envolvem sequência. A ideia por trás do bloco de memória do LSTM é manter o estado durante um período e regular o fluxo de informação através das portas, de modo que a saída do bloco seja recursivamente ligada à entrada do próximo bloco e suas portas. A Figura 4 mostra essa arquitetura, que envolve o sinal de entrada x (t), a informação atual h (t) e a saída y (t) no instante t da célula.